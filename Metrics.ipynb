{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed72948-3ad2-4af3-a1f4-2fa3ecf1a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db31c80-4052-4997-9cea-3a73eded5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для подсчета метрики METEOR использования необходимо скачать \n",
    "#.jar https://mvnrepository.com/artifact/edu.cmu/Meteor/1.5\n",
    "\n",
    "# Аргументы вызова:\n",
    "# records - Dataset с колонками \"summary\" - исходное краткое содержание и \"text\" - исходный текст\n",
    "# predict_func(text, summary) - функция, генерирующая краткое содержание для исходного текста\n",
    "def calc_method_score(records, predict_func, meteor_jar=\"meteor-1.5/meteor-1.5.jar\"):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    for i, record in enumerate(records):\n",
    "        references.append(record[\"summary\"])\n",
    "        predictions.append(predict_func(record[\"text\"], record[\"summary\"]))\n",
    "\n",
    "    for i, (ref, hyp) in enumerate(zip(references, predictions)):\n",
    "        references[i], predictions[i] = postprocess(ref, hyp, tokenize_after=True, lower=True)\n",
    "    print_metrics(references, predictions, meteor_jar=meteor_jar)\n",
    "\n",
    "\n",
    "def calc_bert_score(records, predict_func, nrows=None):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    for i, record in enumerate(records):\n",
    "        if nrows is not None and i >= nrows:\n",
    "            break\n",
    "        references.append(record[\"summary\"])\n",
    "        predictions.append(predict_func(record[\"text\"], record[\"summary\"]))\n",
    "\n",
    "    for i, (ref, hyp) in enumerate(zip(references, predictions)):\n",
    "        references[i], predictions[i] = postprocess(ref, hyp, tokenize_after=False, lower=False)\n",
    "    print_metrics(references, predictions, meteor_jar=None, metric=\"bert_score\")\n",
    "\n",
    "def print_metrics(refs, hyps,metric=\"all\", meteor_jar=None):\n",
    "    metrics = calc_metrics(refs, hyps, metric=metric, meteor_jar=meteor_jar)\n",
    "\n",
    "    print(\"-------------METRICS-------------\")\n",
    "    print(\"Count:\\t\", metrics[\"count\"])\n",
    "    print(\"Ref:\\t\", metrics[\"ref_example\"])\n",
    "    print(\"Hyp:\\t\", metrics[\"hyp_example\"])\n",
    "\n",
    "    if \"bleu\" in metrics:\n",
    "        print(\"BLEU:     \\t{:3.1f}\".format(metrics[\"bleu\"] * 100.0))\n",
    "    if \"chrf\" in metrics:\n",
    "        print(\"chrF:     \\t{:3.1f}\".format(metrics[\"chrf\"] * 100.0))\n",
    "    if \"rouge-1\" in metrics:\n",
    "        print(\"ROUGE-1-F:\\t{:3.1f}\".format(metrics[\"rouge-1\"]['f'] * 100.0))\n",
    "        print(\"ROUGE-2-F:\\t{:3.1f}\".format(metrics[\"rouge-2\"]['f'] * 100.0))\n",
    "        print(\"ROUGE-L-F:\\t{:3.1f}\".format(metrics[\"rouge-l\"]['f'] * 100.0))\n",
    "    if \"meteor\" in metrics:\n",
    "        print(\"METEOR:   \\t{:3.1f}\".format(metrics[\"meteor\"] * 100.0))\n",
    "    if \"length\" in metrics:\n",
    "        print(\"Avg length:\\t{:3.1f}\".format(metrics[\"length\"]))\n",
    "    for key, value in metrics.items():\n",
    "        if \"bert_score\" not in key:\n",
    "            continue\n",
    "        print(\"{}:\\t{:3.1f}\".format(key, value[\"f\"] * 100.0))\n",
    "\n",
    "def calc_metrics(refs, hyps, metric=\"all\",meteor_jar=None):\n",
    "    metrics = dict()\n",
    "    metrics[\"count\"] = len(hyps)\n",
    "    metrics[\"ref_example\"] = refs[-1]\n",
    "    metrics[\"hyp_example\"] = hyps[-1]\n",
    "    many_refs = [[r] if r is not list else r for r in refs]\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        t_hyps = [hyp.split(\" \") for hyp in hyps]\n",
    "        t_refs = [[r.split(\" \") for r in rs] for rs in many_refs]\n",
    "        metrics[\"bleu\"] = corpus_bleu(t_refs, t_hyps)\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "        metrics.update(scores)\n",
    "    if metric in (\"meteor\", \"all\") and meteor_jar is not None and os.path.exists(meteor_jar):\n",
    "        meteor = Meteor(meteor_jar, language='ru')\n",
    "        metrics[\"meteor\"] = meteor.compute_score(hyps, many_refs)\n",
    "    if metric in (\"bert_score\",) and torch.cuda.is_available():\n",
    "        bert_scores, hash_code = calc_bert_score(hyps, refs)\n",
    "        metrics[\"bert_score_{}\".format(hash_code)] = bert_scores\n",
    "    if metric in (\"chrf\", \"all\"):\n",
    "        metrics[\"chrf\"] = corpus_chrf(refs, hyps, beta=1.0)\n",
    "    if metric in (\"length\", \"all\"):\n",
    "        metrics[\"length\"] = mean([len(h) for h in hyps])\n",
    "    return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
