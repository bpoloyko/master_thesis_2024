{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28251d1d-3a93-4d1b-a15c-fe5263f8a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, load_metric\n",
    "import numpy as np\n",
    "import nltk\n",
    "from transformers import AutoTokenizer, T5TokenizerFast, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59a570-9585-48df-afea-97da885aa137",
   "metadata": {},
   "source": [
    "# –í–∞—Ä–∏–∞–Ω—Ç 1. –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π fine-tune –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab95f67-b364-4bc3-81a8-3285625a3d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeta = load_dataset(\"IlyaGusev/gazeta\", revision=\"v2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05223e4b-8c1b-4233-9651-69424e240cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∫–æ–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª—å—é\n",
    "def encode_data(input_sequences):\n",
    "  task_prefix = \"summarize: \"\n",
    "  if type(input_sequences) != list: \n",
    "    input_sequences = [input_sequences]\n",
    "  encoded = tokenizer(\n",
    "    [task_prefix + sequence for sequence in input_sequences],\n",
    "    padding=\"longest\",\n",
    "    max_length=max_input,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",)\n",
    "  return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "101936f8-e325-4ee6-99bd-56abf03fb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#—Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n",
    "def encode_dataset(dataset, max_output = 64):\n",
    "    INPUT_IDS = []\n",
    "    ATTENTION_MASK = []\n",
    "    LABELS = []\n",
    "    for i in range(len(dataset)):\n",
    "        encoded_row = encode_data(dataset[i]['text'])\n",
    "        input_ids, attention_mask = encoded_row.input_ids, encoded_row.attention_mask\n",
    "        target_encoding = tokenizer(dataset[i]['summary'], padding=\"longest\", max_length=max_output, truncation=True)\n",
    "        labels = target_encoding.input_ids\n",
    "        labels = torch.tensor(labels)\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "        INPUT_IDS.append(input_ids)\n",
    "        ATTENTION_MASK.append(ATTENTION_MASK)\n",
    "        LABELS.append(labels)\n",
    "    data = Dataset.from_pandas(pd.DataFrame({'input_ids': list(np.array(INPUT_IDS)), 'attention_mask': list(np.array(ATTENTION_MASK)), 'labels': list(np.array(LABELS))}))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23fe0004-74aa-43b4-bc90-5c97d6aa04a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60964"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gazeta['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbfd3d-bfc4-4a21-b514-8426ef0ae4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_gazeta = encode_dataset(gazeta['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df7d1e5-dfb1-4f2a-9a5c-a9030aeaf571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87f7d71f6e048b381aaad22731f83e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35faf5152bba4259abcf133bf92a302b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb138291ecd49198d15d3ca6e8e2a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d799147f554d87af7a0b6d5882f53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/49.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d1ed23fcc2423c9ddc8d5496e42ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d525f8635e4553b2f0613fc518ee01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca423cc92024008a2fd57d4a561c5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/10.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c55d80f0e54683b119b9d37ec9102a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fc6eecf6c444aa9475823cbcf125db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/452275 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc56b96f2c634a539747595e8b36f31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/23804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "urukhan = load_dataset('UrukHan/t5-russian-summarization' )\n",
    "urukhan_train = urukhan['train']\n",
    "urukhan_test = urukhan['test'].train_test_split(0.02)['test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ad3ca3-5915-4e73-a69d-18f2788c317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Boris\\AppData\\Local\\Temp\\ipykernel_12644\\2179309921.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"rouge\")\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Boris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"rouge\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38102403-3844-432e-bfb2-7bfa8bdae978",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'UrukHan/t5-russian-summarization' # –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace Hub\n",
    "max_input = 1024  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–Ω–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–≤ —Ç–æ–∫–µ–Ω–∞—Ö)\n",
    "max_output  = 64  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è (–≤ —Ç–æ–∫–µ–Ω–∞—Ö)\n",
    "batch_size = 8 \n",
    "output_dir = 'tmp_trainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e164866-c195-4299-bfc0-346874ae26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db44c4b-75e8-48aa-9015-0f95ad06dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.max_length = max_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2baa99-48bd-482e-bd97-37fbe2a3f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = gazeta['train']\n",
    "test = gazeta['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c4ce28-122e-4806-a419-83500a7885d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "  decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "  result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "  result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "  \n",
    "  return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51624ab-20e4-4606-8ff6-75460abc9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–ù–ò–ú–ê–ù–ò–ï! –ù–£–ñ–ù–ê CUDA. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Google Collabs\n",
    "# pip install transformers[torch]\n",
    "\n",
    "# test = urukhan_test\n",
    "# train = urukhan_train\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir = output_dir,\n",
    "  evaluation_strategy='steps',\n",
    "  #learning_rate=2e-5,\n",
    "  eval_steps=5000,\n",
    "  save_steps=5000,\n",
    "  num_train_epochs=1,\n",
    "  predict_with_generate=True,\n",
    "  per_device_train_batch_size=batch_size,\n",
    "  per_device_eval_batch_size=batch_size,\n",
    "  fp16=True,\n",
    "  save_total_limit=2,\n",
    "  #generation_max_length=256,\n",
    "  #generation_num_beams=4,\n",
    "  weight_decay=0.005,\n",
    "  #logging_dir='logs',\n",
    ")\n",
    "\n",
    "# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=0.0,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False,\n",
    ")\n",
    "lr_scheduler = AdafactorSchedule(optimizer)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset = train,\n",
    "  eval_dataset = test,\n",
    "  optimizers = (optimizer, lr_scheduler),\n",
    "  tokenizer = tokenizer,\n",
    "  compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27a3b9-1d11-440e-af56-d0d4913be9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be8742-64a7-4db4-a7f0-984196ced45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.generate(encode(input_sequences)) \n",
    "\n",
    "decoded = tokenizer.batch_decode(predicts, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2301d2e-c706-4e20-9a83-36a3885b94c3",
   "metadata": {},
   "source": [
    "# –í–∞—Ä–∏–∞–Ω—Ç 2. –ü—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4360b3d-203e-4f42-891f-2f48a8ac6ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, T5ForConditionalGeneration \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('RussianNLP/FRED-T5-Summarizer',eos_token='</s>')\n",
    "model = T5ForConditionalGeneration.from_pretrained('RussianNLP/FRED-T5-Summarizer')\n",
    "device='cuda'\n",
    "model.to(device)\n",
    "\n",
    "input_text='<LM> –°–æ–∫—Ä–∞—Ç–∏ —Ç–µ–∫—Å—Ç.\\n –¢–µ–∫—Å—Ç (–æ—Ç –ª–∞—Ç. textus ‚Äî —Ç–∫–∞–Ω—å; —Å–ø–ª–µ—Ç–µ–Ω–∏–µ, —Å–æ—á–µ—Ç–∞–Ω–∏–µ) ‚Äî –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∫–∞–∫–æ–º-–ª–∏–±–æ –º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–º –Ω–æ—Å–∏—Ç–µ–ª–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è –º—ã—Å–ª—å; –≤ –æ–±—â–µ–º –ø–ª–∞–Ω–µ —Å–≤—è–∑–Ω–∞—è –∏ –ø–æ–ª–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤. –°—É—â–µ—Å—Ç–≤—É—é—Ç –¥–≤–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–∞–∫—Ç–æ–≤–∫–∏ –ø–æ–Ω—è—Ç–∏—è ¬´—Ç–µ–∫—Å—Ç¬ª: –∏–º–º–∞–Ω–µ–Ω—Ç–Ω–∞—è (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è, —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏ –Ω–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è) –∏ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–∞—è (–±–æ–ª–µ–µ —á–∞—Å—Ç–Ω–∞—è). –ò–º–º–∞–Ω–µ–Ω—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Ç–µ–∫—Å—Ç—É –∫–∞–∫ –∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏, –Ω–∞—Ü–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –≤—ã—è–≤–ª–µ–Ω–∏–µ –µ–≥–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã. –†–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã–π ‚Äî —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–∞–∫ –æ—Å–æ–±–æ–π —Ñ–æ—Ä–º—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–Ω–µ—à–Ω–µ–π —Ç–µ–∫—Å—Ç—É –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.'\n",
    "input_ids=torch.tensor([tokenizer.encode(input_text)]).to(device)\n",
    "outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,\n",
    "                    num_beams=5,\n",
    "                    min_new_tokens=17,\n",
    "                    max_new_tokens=200,\n",
    "                    do_sample=True,\n",
    "                    no_repeat_ngram_size=4,\n",
    "                    top_p=0.9)\n",
    "print(tokenizer.decode(outputs[0][1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
